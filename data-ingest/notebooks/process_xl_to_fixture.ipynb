{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads a spreadsheet from an excel, cleans it and converts it into a fixture compatible with the DB schema defined in Django.\n",
    "  \n",
    "A cleaning function which accepts a panda's df and return a pandas dataframe is defined for each individual sheet.  \n",
    "  \n",
    "To process more sheets. define a new cleaning function and add it to the `cleaning_func_factory` function, following the consistent naming convention. functions are typically named in the format `def clean_df_{FILE_NAME}_{SHEET_NAME}(df):`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "sys.path.append('../src')\n",
    "\n",
    "import utils\n",
    "\n",
    "from fixtures import df_to_json_list, write_fixture_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pandas_excel(fname):\n",
    "    \n",
    "    fldr_path = '..','data','raw'\n",
    "    fpath = os.path.join(*fldr_path, fname)\n",
    "    xl = pd.ExcelFile(fpath)\n",
    "    \n",
    "    return xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sheet_from_xl(fname, sheet_name):\n",
    "    \"\"\"\n",
    "    load sheet from xl file\n",
    "    \"\"\"\n",
    "    xl = load_pandas_excel(fname)\n",
    "    df = xl.parse(sheet_name)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_clean_df(df):\n",
    "    \"\"\"\n",
    "    drop NaN rows & duplicates, set_index and convert col names to camel case\n",
    "    generic dataframe cleaning function for sheets that need no special renaming or index mapping\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.dropna(how='all')\n",
    "    df = df.drop_duplicates()\n",
    "    df.columns = [utils.convert_to_camelcase(col) for col in df.columns]\n",
    "    \n",
    "    if 'index' in df.columns:\n",
    "        df['index'] = df['index'].astype(int)\n",
    "        df = df.set_index('index')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_resources_languages(df):\n",
    "    \n",
    "    cols_to_keep = ['index', 'language','index_language', 'equivalentClasses',]   # language hyperlinks example url https://bioportal.bioontology.org/ontologies/SNOMEDCT/?p=classes&conceptid=http%3A%2F%2Fpurl.bioontology.org%2Fontology%2FSNOMEDCT%2F297301005\n",
    "    df = df.loc[: ,cols_to_keep]\n",
    "\n",
    "    #handle NaNs\n",
    "    df['index_language'] = df['index_language'].astype(pd.Int64Dtype()) # allows column to have NaNs pd.Int64Dtype()\n",
    "    df['equivalentClasses'] = df['equivalentClasses'].astype(str)\n",
    "    \n",
    "    #rename cols # to avoid a naming clashes in django.\n",
    "    rename_dict = {'language':'name', \n",
    "                   'index_language':'parent_language'}\n",
    "    \n",
    "    df = df.rename(columns=rename_dict)\n",
    "    \n",
    "    df = generic_clean_df(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_disorders_disorder_categories(df):\n",
    "    \n",
    "    cols_to_keep = ['index', 'disorder_category']   # language hyperlinks example url https://bioportal.bioontology.org/ontologies/SNOMEDCT/?p=classes&conceptid=http%3A%2F%2Fpurl.bioontology.org%2Fontology%2FSNOMEDCT%2F297301005\n",
    "    df = df.loc[: ,cols_to_keep]\n",
    "\n",
    "    df = generic_clean_df(df)\n",
    "    \n",
    "    #rename cols # to avoid a naming clashes in django.\n",
    "    rename_dict = {'disorder_category':'name'}\n",
    "    df = df.rename(columns=rename_dict)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_surname_and_initials_from_string(in_string):\n",
    "    \"\"\"use regex to extract inidividual author names & initials from list of authors\n",
    "    returns: list of tuples, [(surname, first_initial, middle_initial),]\n",
    "    \n",
    "    example: in_string='Achenbach, T. M., & Rescorla, L. A.'\n",
    "            returns [('Achenbach','T','M'), ('Rescorla','L','A')]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    expression = \"([A-Z][a-z]+?[A-Za-z\\s]+)([,]?)([\\s]?)([A-Za-z]?)([.]?[,\\s]?)([A-Z]?[,]?)\"\n",
    "    matches = re.findall(expression, in_string)\n",
    "\n",
    "    names_lst = []\n",
    "    for match in matches:\n",
    "        surname = match[0]\n",
    "        first_initial =  match[3]\n",
    "        middle_initial = match[-1]\n",
    "        \n",
    "        names_lst.append((surname, first_initial, middle_initial ))\n",
    "    \n",
    "    return names_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_names_df_from_author_lists(ser_authors):\n",
    "    \"\"\"\n",
    "    ser_authors:pd.Series, with lists of authors as a string\n",
    "    returns: pd.DataFrame with column 'surname','first_initial','middle_initial'\n",
    "    \"\"\"\n",
    "\n",
    "    ser_authors = ser_authors.drop_duplicates().dropna()\n",
    "    ser_authors = ser_authors.astype(str)\n",
    "\n",
    "    overall_authors_lst = []\n",
    "\n",
    "    for auth_lst in ser_authors:\n",
    "        # add each set of match results to the overall list\n",
    "        overall_authors_lst += get_surname_and_initials_from_string(auth_lst)\n",
    "\n",
    "    df = pd.DataFrame(overall_authors_lst, columns = ['surname','first_initial','middle_initial',] )\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_authors_fixture():\n",
    "    \"\"\"\n",
    "    special case function to create an authors fixture\n",
    "    \"\"\"\n",
    "    sheet_name = 'questionnaires'\n",
    "    input_fname = 'assessments.xlsx'\n",
    "    app_name = 'assessments'\n",
    "    model_name = 'Author'\n",
    "    output_fname = 'Author.json'\n",
    "    df = load_sheet_from_xl(input_fname, sheet_name)\n",
    "\n",
    "    ser_authors = df['authors']\n",
    "    df = make_names_df_from_author_lists(ser_authors)\n",
    "    df = df.replace('',np.nan)\n",
    "    \n",
    "    fname, fixture_lst = df_to_json_list(df,\n",
    "                                        app_name,\n",
    "                                        model_name,\n",
    "                                        file_name_modifier='',\n",
    "                                        use_df_index_as_pk=False,\n",
    "                                        create_datetimefield_name=None,\n",
    "                                        created_by_field_name=None)\n",
    "    write_fixture_to_json(fixture_lst, output_fname, output_folder='default')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_disorders_severities(df):\n",
    "\n",
    "    df = df.set_index('index')\n",
    "    keep_cols = ['severity', 'definition']\n",
    "    df = df.loc[:,keep_cols]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_disorders_disorders(df):\n",
    "\n",
    "    keep_cols = ['S',\n",
    "                 'index_disorder_category',\n",
    "                #  'index_disorder_subcategory',\n",
    "                #  'index_disorder_subsubcategory',\n",
    "                #  'index_disorder_subsubsubcategory',\n",
    "                 'disorder',\n",
    "                #  'equivalentClasses',\n",
    "                 'ICD9CM',\n",
    "                 'ICD10CM',\n",
    "                 'index_diagnostic_specifier',\n",
    "                #  'index_diagnostic_inclusion_criterion',\n",
    "                #  'index_diagnostic_inclusion_criterion2',\n",
    "                #  'index_diagnostic_exclusion_criterion',\n",
    "                #  'index_diagnostic_exclusion_criterion2',\n",
    "                 'index_severity',\n",
    "                 'note']\n",
    "\n",
    "    df = df.loc[:, keep_cols]\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    df['s'] = df['s'].astype(int)\n",
    "    df = df.rename(columns={'s':'index'})\n",
    "    \n",
    "    df = generic_clean_df(df)\n",
    "\n",
    "    df['index_severity'] = df['index_severity'].astype(pd.Int64Dtype())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_disorders_diagnostic_specifiers(df):\n",
    "\n",
    "    df['equivalentClasses'] = df['equivalentClasses'].astype(str)\n",
    "    df = generic_clean_df(df)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_func_factory(fname, sheet_name):\n",
    "    \"\"\"\n",
    "    return the appropriate df cleaning function by looking up a dictionary\n",
    "    the functions should be saved in the dictionary in the format FileName__SheetName\n",
    "    \"\"\"\n",
    "    file_sheet = fname.split('.')[0] + \"__\" + sheet_name\n",
    "    \n",
    "    cleaning_funcs = {}\n",
    "    cleaning_funcs[\"resources__languages\"] = clean_df_resources_languages\n",
    "    cleaning_funcs[\"disorders__disorder_categories\"] = clean_df_disorders_disorder_categories\n",
    "    cleaning_funcs['disorders__severities'] = clean_df_disorders_severities\n",
    "    cleaning_funcs['disorders__disorders'] = clean_df_disorders_disorders\n",
    "    cleaning_funcs['disorders__diagnostic_specifiers'] = clean_df_disorders_diagnostic_specifiers\n",
    "    cleaning_funcs['disorders__diagnostic_criteria'] = generic_clean_df\n",
    "#     cleaning_funcs[''] = \n",
    "    \n",
    "    return cleaning_funcs[file_sheet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_sheet(fname, sheet_name, app_name, model_name):\n",
    "    \n",
    "    df = load_sheet_from_xl(fname, sheet_name)\n",
    "    # look up the cleaning function based on file and sheet name \n",
    "    df = cleaning_func_factory(fname, sheet_name)(df)\n",
    "\n",
    "    fname, fixture_lst = df_to_json_list(df,\n",
    "                                        app_name,\n",
    "                                        model_name,\n",
    "                                        file_name_modifier='',\n",
    "                                        use_df_index_as_pk=True,\n",
    "                                        create_datetimefield_name=None,\n",
    "                                        created_by_field_name=None)\n",
    "\n",
    "    write_fixture_to_json(fixture_lst, fname, output_folder='default')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_unique_col_vals_from_excel(pandas_xl, col_name):\n",
    "    \"\"\"\n",
    "    iterate through all sheets of a pandas ExcelFile object and return\n",
    "    a series that concates all columns with the name col_name\n",
    "    col_name:str, name of column that is in multiple sheets\n",
    "    pandas_xl:pd.ExcelFile\n",
    "    \n",
    "    returns pd.Series\n",
    "    \"\"\"\n",
    "    sheet_names = pandas_xl.sheet_names  # see all sheet names\n",
    "\n",
    "    ser_lst = []\n",
    "    col_found_count=0\n",
    "\n",
    "    for sheet_name in sheet_names:\n",
    "        df = pandas_xl.parse(sheet_name)\n",
    "        if col_name in df.columns:\n",
    "            col_found_count+=1\n",
    "\n",
    "            ser = df[col_name].dropna(how='any')\n",
    "            ser_lst.append(ser)\n",
    "\n",
    "    ser_all = pd.concat(ser_lst).drop_duplicates().dropna(how='any')\n",
    "    print(f\"column '{col_name}' found in {col_found_count} sheets\")\n",
    "    \n",
    "    \n",
    "    return ser_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_comma_separated_series(ser, drop_duplicates=True):\n",
    "    \"\"\"\n",
    "    accept a series with entries containing comma separated values.\n",
    "    split and return series where entries are individual values\n",
    "    drops duplicated values by default\n",
    "    \n",
    "    ser: pd.Series\n",
    "    \"\"\"\n",
    "    \n",
    "    ser = ser.astype(str).str.split(',')\n",
    "    \n",
    "    flat_lst = []  \n",
    "    for lst in ser:\n",
    "        flat_lst.extend(lst) \n",
    "    \n",
    "    ser = pd.Series(flat_lst, name=ser.name)\n",
    "    \n",
    "    ser = ser.dropna(how='any')\n",
    "    ser = ser.str.strip(to_strip=' ')\n",
    "\n",
    "    if drop_duplicates:\n",
    "        ser = ser.drop_duplicates()\n",
    "\n",
    "    return ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_all_unique_col_vals_to_fixture(pandas_xl, col_name, app_name, col_case_func=str.lower):\n",
    "    \"\"\"\n",
    "    col_name:str, name of column that is in multiple sheets\n",
    "    pandas_xl:pd.ExcelFile\n",
    "    app_name: str, app name in django\n",
    "    returns pd.Series\n",
    "    \n",
    "    \"\"\"\n",
    "    model_name = col_name.title() \n",
    "\n",
    "    ser = get_all_unique_col_vals_from_excel(pandas_xl, col_name)\n",
    "    ser = split_comma_separated_series(ser)\n",
    "    ser = ser.sort_values(ignore_index=True)\n",
    "    if col_case_func:\n",
    "        ser.name = col_case_func(ser.name)\n",
    "    \n",
    "    df = ser.to_frame()\n",
    "\n",
    "    output_fname, fixture_lst = df_to_json_list(df,\n",
    "                                        app_name,\n",
    "                                        model_name,\n",
    "                                        file_name_modifier='',\n",
    "                                        use_df_index_as_pk=False,\n",
    "                                        create_datetimefield_name=None,\n",
    "                                        created_by_field_name=None)\n",
    "    write_fixture_to_json(fixture_lst, output_fname, output_folder='default')\n",
    "    \n",
    "    return fixture_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporary Working Space\n",
    "remove this section before converting to .py script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputs = {\n",
    "    'sheet_name' : 'diagnostic_criteria',\n",
    "    'fname' : 'disorders.xlsx',\n",
    "    'model_name' : 'DiagnosticCriterion',\n",
    "    'app_name' : 'disorders',\n",
    "    }\n",
    "\n",
    "sheet_name = inputs['sheet_name']\n",
    "fname = inputs['fname']\n",
    "model_name = inputs['model_name']\n",
    "app_name = inputs['app_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote fixture to ../data/processed/fixtures/Author.json\n"
     ]
    }
   ],
   "source": [
    "# special case functions for making tables that did not already have their ownsheet\n",
    "create_authors_fixture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column 'ICD9CM' found in 5 sheets\n",
      "wrote fixture to ../data/processed/fixtures/Icd9Cm.json\n",
      "column 'ICD10CM' found in 5 sheets\n",
      "wrote fixture to ../data/processed/fixtures/Icd10Cm.json\n"
     ]
    }
   ],
   "source": [
    "# make fixtures for reference columns that appear in mutliple sheets of a file\n",
    "inputs = [\n",
    "    {\n",
    "    'fname' : 'disorders.xlsx',\n",
    "    'col_names':['ICD9CM','ICD10CM'],\n",
    "    'app_name' : 'disorders'\n",
    "    },\n",
    "    ]\n",
    "\n",
    "for d in inputs:\n",
    "    fname = d['fname']\n",
    "    app_name = d['app_name']\n",
    "    col_names = d['col_names']\n",
    "\n",
    "    pandas_xl = load_pandas_excel(fname)\n",
    "\n",
    "    for col_name in col_names:\n",
    "        fixture_lst = write_all_unique_col_vals_to_fixture(pandas_xl, col_name, app_name, col_case_func=str.lower)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main Sheets export  ###\n",
    "\n",
    "### format example\n",
    "#     {\n",
    "#     'sheet_name' : 'languages',   # as defined in the xl sheet\n",
    "#     'fname' : 'resources.xlsx',   # as defined for the xl file\n",
    "#     'model_name' : 'Language',    # the Django model class name\n",
    "#     'app_name' : 'resources',     # the Django app that the the Model class belongs to\n",
    "#     },\n",
    "\n",
    "# uncomment the dictionaries to run all sheets\n",
    "\n",
    "inputs_lst = [\n",
    "    {\n",
    "    'sheet_name' : 'languages',\n",
    "    'fname' : 'resources.xlsx',\n",
    "    'model_name' : 'Language',\n",
    "    'app_name' : 'resources',\n",
    "    },\n",
    "    {\n",
    "    'sheet_name' : 'disorder_categories',\n",
    "    'fname' : 'disorders.xlsx',\n",
    "    'model_name' : 'DisorderCategory',\n",
    "    'app_name' : 'disorders',\n",
    "    },\n",
    "    {\n",
    "    'sheet_name' : 'severities',\n",
    "    'fname' : 'disorders.xlsx',\n",
    "    'model_name' : 'Severity',\n",
    "    'app_name' : 'disorders',\n",
    "    },\n",
    "    {\n",
    "    'sheet_name' : 'disorders',\n",
    "    'fname' : 'disorders.xlsx',\n",
    "    'model_name' : 'Disorder',\n",
    "    'app_name' : 'disorders',\n",
    "    },\n",
    "    {\n",
    "    'sheet_name' : 'diagnostic_specifiers',\n",
    "    'fname' : 'disorders.xlsx',\n",
    "    'model_name' : 'DiagnosticSpecifier',\n",
    "    'app_name' : 'disorders',\n",
    "    },\n",
    "    {\n",
    "    'sheet_name' : 'diagnostic_criteria',\n",
    "    'fname' : 'disorders.xlsx',\n",
    "    'model_name' : 'DiagnosticCriterion',\n",
    "    'app_name' : 'disorders',\n",
    "    },\n",
    "    \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote fixture to ../data/processed/fixtures/Language.json\n",
      "wrote fixture to ../data/processed/fixtures/DisorderCategory.json\n",
      "wrote fixture to ../data/processed/fixtures/Severity.json\n",
      "wrote fixture to ../data/processed/fixtures/Disorder.json\n",
      "wrote fixture to ../data/processed/fixtures/DiagnosticSpecifier.json\n",
      "wrote fixture to ../data/processed/fixtures/DiagnosticCriterion.json\n"
     ]
    }
   ],
   "source": [
    "for d in inputs_lst:\n",
    "    try: \n",
    "        process_one_sheet(d['fname'], d['sheet_name'], d['app_name'], d['model_name'])\n",
    "    except FileExistsError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
