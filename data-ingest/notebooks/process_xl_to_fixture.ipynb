{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "sys.path.append('../src')\n",
    "\n",
    "from fixtures import df_to_json_list, write_fixture_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sheet_from_xl(fname, sheet_name):\n",
    "    \"\"\"\n",
    "    load sheet from xl file\n",
    "    \"\"\"\n",
    "    fldr_path = '..','data','raw'\n",
    "    fpath = os.path.join(*fldr_path, fname)\n",
    "    xl = pd.ExcelFile(fpath)\n",
    "    df = xl.parse(sheet_name)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_resources_languages(df):\n",
    "    \n",
    "    cols_to_keep = ['index', 'language','index_language', 'equivalentClasses',]   # language hyperlinks example url https://bioportal.bioontology.org/ontologies/SNOMEDCT/?p=classes&conceptid=http%3A%2F%2Fpurl.bioontology.org%2Fontology%2FSNOMEDCT%2F297301005\n",
    "    df = df.loc[: ,cols_to_keep]\n",
    "\n",
    "    #handle NaNs\n",
    "    df['index_language'] = df['index_language'].astype(pd.Int64Dtype()) # allows column to have NaNs pd.Int64Dtype()\n",
    "    df['equivalentClasses'] = df['equivalentClasses'].astype(str)\n",
    "\n",
    "    df = df.set_index('index')\n",
    "    \n",
    "    #rename cols # to avoid a naming clashes in django.\n",
    "    rename_dict = {'language':'name', \n",
    "                   'index_language':'parent_language'}\n",
    "    \n",
    "    df = df.rename(columns=rename_dict)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_disorders_disorder_categories(df):\n",
    "    \n",
    "    cols_to_keep = ['index', 'disorder_category']   # language hyperlinks example url https://bioportal.bioontology.org/ontologies/SNOMEDCT/?p=classes&conceptid=http%3A%2F%2Fpurl.bioontology.org%2Fontology%2FSNOMEDCT%2F297301005\n",
    "    df = df.loc[: ,cols_to_keep]\n",
    "\n",
    "    #handle NaNs\n",
    "    df = df.dropna()\n",
    "    df = df.set_index('index')\n",
    "    \n",
    "    #rename cols # to avoid a naming clashes in django.\n",
    "    rename_dict = {'disorder_category':'name'}\n",
    "    df = df.rename(columns=rename_dict)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_authors_df():\n",
    "    \"\"\"\n",
    "    the authors column in the questionnaires__assessments sheet has been entered as free text.\n",
    "    This function creates a dataframe of individual authors to be used to popoulate an authors table\n",
    "    \"\"\"    \n",
    "    sheet_name = 'questionnaires'\n",
    "    fname = 'assessments.xlsx'\n",
    "    \n",
    "    df = load_sheet_from_xl(fname, sheet_name)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_surname_and_initials_from_string(in_string):\n",
    "    \"\"\"use regex to extract inidividual author names & initials from list of authors\n",
    "    returns: list of tuples, [(surname, first_initial, middle_initial),]\n",
    "    \n",
    "    example: in_string='Achenbach, T. M., & Rescorla, L. A.'\n",
    "            returns [('Achenbach','T','M'), ('Rescorla','L','A')]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    expression = \"([A-Z][a-z]+?[A-Za-z\\s]+)([,]?)([\\s]?)([A-Za-z]?)([.]?[,\\s]?)([A-Z]?[,]?)\"\n",
    "    matches = re.findall(expression, in_string)\n",
    "\n",
    "    names_lst = []\n",
    "    for match in matches:\n",
    "        surname = match[0]\n",
    "        first_initial =  match[3]\n",
    "        middle_initial = match[-1]\n",
    "        \n",
    "        names_lst.append((surname, first_initial, middle_initial ))\n",
    "    \n",
    "    return names_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_names_df_from_author_lists(ser_authors):\n",
    "    \"\"\"\n",
    "    ser_authors:pd.Series, with lists of authors as a string\n",
    "    returns: pd.DataFrame with column 'surname','first_initial','middle_initial'\n",
    "    \"\"\"\n",
    "\n",
    "    ser_authors = ser_authors.drop_duplicates().dropna()\n",
    "    ser_authors = ser_authors.astype(str)\n",
    "\n",
    "    overall_authors_lst = []\n",
    "\n",
    "    for auth_lst in ser_authors:\n",
    "        # add each set of match results to the overall list\n",
    "        overall_authors_lst += get_surname_and_initials_from_string(auth_lst)\n",
    "\n",
    "    df = pd.DataFrame(overall_authors_lst, columns = ['surname','first_initial','middle_initial',] )\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_authors_fixture():\n",
    "    \"\"\"\n",
    "    special case function to create an authors fixture\n",
    "    \"\"\"\n",
    "    sheet_name = 'questionnaires'\n",
    "    input_fname = 'assessments.xlsx'\n",
    "    app_name = 'assessments'\n",
    "    model_name = 'Author'\n",
    "    output_fname = 'Author.json'\n",
    "    df = load_sheet_from_xl(input_fname, sheet_name)\n",
    "\n",
    "    ser_authors = df['authors']\n",
    "    df = make_names_df_from_author_lists(ser_authors)\n",
    "    df = df.replace('',np.nan)\n",
    "    \n",
    "    fname, fixture_lst = df_to_json_list(df,\n",
    "                                        app_name,\n",
    "                                        model_name,\n",
    "                                        file_name_modifier='',\n",
    "                                        use_df_index_as_pk=False,\n",
    "                                        create_datetimefield_name=None,\n",
    "                                        created_by_field_name=None)\n",
    "    write_fixture_to_json(fixture_lst, output_fname, output_folder='default')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_disorders_severities(df):\n",
    "\n",
    "    df = df.set_index('index')\n",
    "    keep_cols = ['severity', 'definition']\n",
    "    df = df.loc[:,keep_cols]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_disorders_disorders(df):\n",
    "\n",
    "    keep_cols = ['S',\n",
    "                 'index_disorder_category',\n",
    "                #  'index_disorder_subcategory',\n",
    "                #  'index_disorder_subsubcategory',\n",
    "                #  'index_disorder_subsubsubcategory',\n",
    "                 'disorder',\n",
    "                #  'equivalentClasses',\n",
    "                 'ICD9CM',\n",
    "                 'ICD10CM',\n",
    "                 'index_diagnostic_specifier',\n",
    "                #  'index_diagnostic_inclusion_criterion',\n",
    "                #  'index_diagnostic_inclusion_criterion2',\n",
    "                #  'index_diagnostic_exclusion_criterion',\n",
    "                #  'index_diagnostic_exclusion_criterion2',\n",
    "                 'index_severity',\n",
    "                 'note']\n",
    "\n",
    "    df = df.loc[:, keep_cols]\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    df['s'] = df['s'].astype(int)\n",
    "    df = df.rename(columns={'s':'index'})\n",
    "    df = df.set_index('index')\n",
    "\n",
    "    df['index_severity'] = df['index_severity'].astype(pd.Int64Dtype())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_disorders_diagnostic_specifiers(df):\n",
    "\n",
    "    df = df.dropna(how='all')\n",
    "    df = df.set_index('index')\n",
    "    df['equivalentClasses'] = df['equivalentClasses'].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_func_factory(fname, sheet_name):\n",
    "    \"\"\"\n",
    "    return the appropriate df cleaning function by looking up a dictionary\n",
    "    the functions should be saved in the dictionary in the format FileName__SheetName\n",
    "    \"\"\"\n",
    "    file_sheet = fname.split('.')[0] + \"__\" + sheet_name\n",
    "    \n",
    "    cleaning_funcs = {}\n",
    "    cleaning_funcs[\"resources__languages\"] = clean_df_resources_languages\n",
    "    cleaning_funcs[\"disorders__disorder_categories\"] = clean_df_disorders_disorder_categories\n",
    "    cleaning_funcs['disorders__severities'] = clean_df_disorders_severities\n",
    "    cleaning_funcs['disorders__disorders'] = clean_df_disorders_disorders\n",
    "    cleaning_funcs['disorders__diagnostic_specifiers'] = clean_df_disorders_diagnostic_specifiers\n",
    "#     cleaning_funcs[''] = \n",
    "    \n",
    "    return cleaning_funcs[file_sheet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_sheet(fname, sheet_name, app_name, model_name):\n",
    "    \n",
    "    df = load_sheet_from_xl(fname, sheet_name)\n",
    "    # look up the cleaning function based on file and sheet name \n",
    "    df = cleaning_func_factory(fname, sheet_name)(df)\n",
    "\n",
    "    fname, fixture_lst = df_to_json_list(df,\n",
    "                                        app_name,\n",
    "                                        model_name,\n",
    "                                        file_name_modifier='',\n",
    "                                        use_df_index_as_pk=True,\n",
    "                                        create_datetimefield_name=None,\n",
    "                                        created_by_field_name=None)\n",
    "\n",
    "    write_fixture_to_json(fixture_lst, fname, output_folder='default')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'sheet_name' : 'diagnostic_specifiers',\n",
    "    'fname' : 'disorders.xlsx',\n",
    "    'model_name' : 'DiagnosticSpecifier',\n",
    "    'app_name' : 'disorders',\n",
    "    }\n",
    "\n",
    "sheet_name = inputs['sheet_name']\n",
    "fname = inputs['fname']\n",
    "model_name = inputs['model_name']\n",
    "app_name = inputs['app_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_sheet_from_xl(fname, sheet_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_df_disorders_diagnostic_specifiers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the dictionaries to run all sheets\n",
    "\n",
    "inputs_lst = [\n",
    "#     {\n",
    "#     'sheet_name' : 'languages',\n",
    "#     'fname' : 'resources.xlsx',\n",
    "#     'model_name' : 'Language',\n",
    "#     'app_name' : 'resources',\n",
    "#     },\n",
    "#     {\n",
    "#     'sheet_name' : 'disorder_categories',\n",
    "#     'fname' : 'disorders.xlsx',\n",
    "#     'model_name' : 'DisorderCategory',\n",
    "#     'app_name' : 'disorders',\n",
    "#     },\n",
    "#     {\n",
    "#     'sheet_name' : 'severities',\n",
    "#     'fname' : 'disorders.xlsx',\n",
    "#     'model_name' : 'Severity',\n",
    "#     'app_name' : 'disorders',\n",
    "#     },\n",
    "#     {\n",
    "#     'sheet_name' : 'disorders',\n",
    "#     'fname' : 'disorders.xlsx',\n",
    "#     'model_name' : 'Disorder',\n",
    "#     'app_name' : 'disorders',\n",
    "#     },\n",
    "    {\n",
    "    'sheet_name' : 'diagnostic_specifiers',\n",
    "    'fname' : 'disorders.xlsx',\n",
    "    'model_name' : 'DiagnosticSpecifier',\n",
    "    'app_name' : 'disorders',\n",
    "    }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote fixture to ../data/processed/fixtures/DiagnosticSpecifier.json\n"
     ]
    }
   ],
   "source": [
    "for d in inputs_lst:\n",
    "    try: \n",
    "        process_one_sheet(d['fname'], d['sheet_name'], d['app_name'], d['model_name'])\n",
    "    except FileExistsError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote fixture to ../data/processed/fixtures/Author.json\n"
     ]
    }
   ],
   "source": [
    "create_authors_fixture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
